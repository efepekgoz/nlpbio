{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red183\green111\blue179;\red23\green23\blue23;\red202\green202\blue202;
\red212\green212\blue212;\red70\green137\blue204;\red212\green214\blue154;\red140\green211\blue254;\red167\green197\blue152;
\red113\green184\blue255;\red67\green192\blue160;\red194\green126\blue101;\red89\green156\blue62;}
{\*\expandedcolortbl;;\cssrgb\c77255\c52549\c75294;\cssrgb\c11765\c11765\c11765;\cssrgb\c83137\c83137\c83137;
\cssrgb\c86275\c86275\c86275;\cssrgb\c33725\c61176\c83922;\cssrgb\c86275\c86275\c66667;\cssrgb\c61176\c86275\c99608;\cssrgb\c70980\c80784\c65882;
\cssrgb\c50980\c77647\c100000;\cssrgb\c30588\c78824\c69020;\cssrgb\c80784\c56863\c47059;\cssrgb\c41569\c66275\c30980;}
\paperw11900\paperh16840\margl1440\margr1440\vieww14760\viewh8280\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Cross Entropy Loss:\
Epoch 100, Training Loss: 1.0543, Training Accuracy: 81.15%, Validation Loss: 0.9416, Validation Accuracy: 84.08%\
Test Loss: 0.9721, Test Accuracy: 84.68%\
Multi Class Hinge Loss:\
Epoch 100, Training Loss: 0.3545, Training Accuracy: 82.42%, Validation Loss: 0.3017, Validation Accuracy: 85.22%\
Test Loss: 0.2890, Test Accuracy: 85.84%\
\
\
Working train\
\
\pard\pardeftab720\partightenfactor0

\f1\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 from\cf4 \strokec4  sklearn.metrics \cf2 \strokec2 import\cf4 \strokec4  precision_recall_curve\cf5 \strokec5 ,\cf4 \strokec4  confusion_matrix\cf5 \strokec5 ,\cf4 \strokec4  ConfusionMatrixDisplay\cf5 \strokec5 ,\cf4 \strokec4  f1_score\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 def\cf4 \strokec4  \cf7 \strokec7 train_epoch\cf4 \strokec4 (\cf8 \strokec8 model\cf4 \strokec4 , \cf8 \strokec8 data_loader\cf4 \strokec4 , \cf8 \strokec8 optimizer\cf4 \strokec4 , \cf8 \strokec8 loss_fn\cf4 \strokec4 )\cf5 \strokec5 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     model.train\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\cb3     total_train_loss = \cf9 \strokec9 0\cf4 \cb1 \strokec4 \
\cb3     total_correct = \cf9 \strokec9 0\cf4 \cb1 \strokec4 \
\cb3     total_tokens = \cf9 \strokec9 0\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf2 \strokec2 for\cf4 \strokec4  tokens\cf5 \strokec5 ,\cf4 \strokec4  ner_tags\cf5 \strokec5 ,\cf4 \strokec4  lengths \cf10 \strokec10 in\cf4 \strokec4  data_loader\cf5 \strokec5 :\cf4 \cb1 \strokec4 \
\cb3         optimizer.zero_grad\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\cb3         outputs = model\cf5 \strokec5 (\cf4 \strokec4 tokens\cf5 \strokec5 ,\cf4 \strokec4  lengths\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3         outputs_reshaped = outputs.view\cf5 \strokec5 (\cf9 \strokec9 -1\cf5 \strokec5 ,\cf4 \strokec4  outputs.shape\cf5 \strokec5 [\cf9 \strokec9 -1\cf5 \strokec5 ])\cf4 \cb1 \strokec4 \
\cb3         ner_tags_reshaped = ner_tags.view\cf5 \strokec5 (\cf9 \strokec9 -1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\
\cb3         loss = loss_fn\cf5 \strokec5 (\cf4 \strokec4 outputs_reshaped\cf5 \strokec5 ,\cf4 \strokec4  ner_tags_reshaped\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3         loss.backward\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\cb3         optimizer.step\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\cb3         \cb1 \
\cb3         total_train_loss += loss.item\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\
\cb3         predictions = torch.argmax\cf5 \strokec5 (\cf4 \strokec4 outputs_reshaped\cf5 \strokec5 ,\cf4 \strokec4  dim=\cf9 \strokec9 1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3         correct_predictions = \cf5 \strokec5 (\cf4 \strokec4 predictions == ner_tags_reshaped\cf5 \strokec5 )\cf4 \strokec4  & \cf5 \strokec5 (\cf4 \strokec4 ner_tags_reshaped != \cf9 \strokec9 -1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3         total_correct += correct_predictions.\cf7 \strokec7 sum\cf5 \strokec5 ()\cf4 \strokec4 .item\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\cb3         total_tokens += \cf5 \strokec5 (\cf4 \strokec4 ner_tags_reshaped != \cf9 \strokec9 -1\cf5 \strokec5 )\cf4 \strokec4 .\cf7 \strokec7 sum\cf5 \strokec5 ()\cf4 \strokec4 .item\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\
\cb3     avg_loss = total_train_loss / \cf7 \strokec7 len\cf5 \strokec5 (\cf4 \strokec4 data_loader\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     accuracy = \cf5 \strokec5 (\cf4 \strokec4 total_correct / total_tokens\cf5 \strokec5 )\cf4 \strokec4  * \cf9 \strokec9 100\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 return\cf4 \strokec4  avg_loss\cf5 \strokec5 ,\cf4 \strokec4  accuracy\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 def\cf4 \strokec4  \cf7 \strokec7 evaluate\cf4 \strokec4 (\cf8 \strokec8 model\cf4 \strokec4 , \cf8 \strokec8 data_loader\cf4 \strokec4 , \cf8 \strokec8 loss_fn\cf4 \strokec4 )\cf5 \strokec5 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     model.\cf7 \strokec7 eval\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\cb3     total_loss = \cf9 \strokec9 0\cf4 \cb1 \strokec4 \
\cb3     total_correct = \cf9 \strokec9 0\cf4 \cb1 \strokec4 \
\cb3     total_tokens = \cf9 \strokec9 0\cf4 \cb1 \strokec4 \
\
\cb3     \cf2 \strokec2 with\cf4 \strokec4  torch.no_grad\cf5 \strokec5 ():\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 for\cf4 \strokec4  tokens\cf5 \strokec5 ,\cf4 \strokec4  ner_tags\cf5 \strokec5 ,\cf4 \strokec4  lengths \cf10 \strokec10 in\cf4 \strokec4  data_loader\cf5 \strokec5 :\cf4 \cb1 \strokec4 \
\cb3             outputs = model\cf5 \strokec5 (\cf4 \strokec4 tokens\cf5 \strokec5 ,\cf4 \strokec4  lengths\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3             outputs_reshaped = outputs.view\cf5 \strokec5 (\cf9 \strokec9 -1\cf5 \strokec5 ,\cf4 \strokec4  outputs.shape\cf5 \strokec5 [\cf9 \strokec9 -1\cf5 \strokec5 ])\cf4 \cb1 \strokec4 \
\cb3             ner_tags_reshaped = ner_tags.view\cf5 \strokec5 (\cf9 \strokec9 -1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\
\cb3             loss = loss_fn\cf5 \strokec5 (\cf4 \strokec4 outputs_reshaped\cf5 \strokec5 ,\cf4 \strokec4  ner_tags_reshaped\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3             total_loss += loss.item\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\
\cb3             predictions = torch.argmax\cf5 \strokec5 (\cf4 \strokec4 outputs_reshaped\cf5 \strokec5 ,\cf4 \strokec4  dim=\cf9 \strokec9 1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3             correct_predictions = \cf5 \strokec5 (\cf4 \strokec4 predictions == ner_tags_reshaped\cf5 \strokec5 )\cf4 \strokec4  & \cf5 \strokec5 (\cf4 \strokec4 ner_tags_reshaped != \cf9 \strokec9 -1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3             total_correct += correct_predictions.\cf7 \strokec7 sum\cf5 \strokec5 ()\cf4 \strokec4 .item\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\cb3             total_tokens += \cf5 \strokec5 (\cf4 \strokec4 ner_tags_reshaped != \cf9 \strokec9 -1\cf5 \strokec5 )\cf4 \strokec4 .\cf7 \strokec7 sum\cf5 \strokec5 ()\cf4 \strokec4 .item\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\
\cb3     avg_loss = total_loss / \cf7 \strokec7 len\cf5 \strokec5 (\cf4 \strokec4 data_loader\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     accuracy = \cf5 \strokec5 (\cf4 \strokec4 total_correct / total_tokens\cf5 \strokec5 )\cf4 \strokec4  * \cf9 \strokec9 100\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 return\cf4 \strokec4  avg_loss\cf5 \strokec5 ,\cf4 \strokec4  accuracy\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 def\cf4 \strokec4  \cf7 \strokec7 evaluate_with_details\cf4 \strokec4 (\cf8 \strokec8 model\cf4 \strokec4 , \cf8 \strokec8 data_loader\cf4 \strokec4 , \cf8 \strokec8 loss_fn\cf4 \strokec4 , \cf8 \strokec8 index2token\cf4 \strokec4 , \cf8 \strokec8 index2tag\cf4 \strokec4 )\cf5 \strokec5 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     model.\cf7 \strokec7 eval\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\cb3     total_loss = \cf9 \strokec9 0\cf4 \cb1 \strokec4 \
\cb3     all_predictions = \cf5 \strokec5 []\cf4 \cb1 \strokec4 \
\cb3     all_true_labels = \cf5 \strokec5 []\cf4 \cb1 \strokec4 \
\cb3     all_tokens = \cf5 \strokec5 []\cf4 \cb1 \strokec4 \
\
\cb3     \cf2 \strokec2 with\cf4 \strokec4  torch.no_grad\cf5 \strokec5 ():\cf4 \cb1 \strokec4 \
\cb3         \cf2 \strokec2 for\cf4 \strokec4  tokens\cf5 \strokec5 ,\cf4 \strokec4  ner_tags\cf5 \strokec5 ,\cf4 \strokec4  lengths \cf10 \strokec10 in\cf4 \strokec4  data_loader\cf5 \strokec5 :\cf4 \cb1 \strokec4 \
\cb3             outputs = model\cf5 \strokec5 (\cf4 \strokec4 tokens\cf5 \strokec5 ,\cf4 \strokec4  lengths\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3             outputs_reshaped = outputs.view\cf5 \strokec5 (\cf9 \strokec9 -1\cf5 \strokec5 ,\cf4 \strokec4  outputs.shape\cf5 \strokec5 [\cf9 \strokec9 -1\cf5 \strokec5 ])\cf4 \cb1 \strokec4 \
\cb3             ner_tags_reshaped = ner_tags.view\cf5 \strokec5 (\cf9 \strokec9 -1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3             loss = loss_fn\cf5 \strokec5 (\cf4 \strokec4 outputs_reshaped\cf5 \strokec5 ,\cf4 \strokec4  ner_tags_reshaped\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3             total_loss += loss.item\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\
\cb3             predictions = torch.argmax\cf5 \strokec5 (\cf4 \strokec4 outputs_reshaped\cf5 \strokec5 ,\cf4 \strokec4  dim=\cf9 \strokec9 1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3             valid_indices = ner_tags_reshaped != \cf9 \strokec9 -1\cf4 \cb1 \strokec4 \
\
\cb3             all_tokens.extend\cf5 \strokec5 (\cf4 \strokec4 tokens.view\cf5 \strokec5 (\cf9 \strokec9 -1\cf5 \strokec5 )[\cf4 \strokec4 valid_indices\cf5 \strokec5 ]\cf4 \strokec4 .tolist\cf5 \strokec5 ())\cf4 \cb1 \strokec4 \
\cb3             all_predictions.extend\cf5 \strokec5 (\cf4 \strokec4 predictions\cf5 \strokec5 [\cf4 \strokec4 valid_indices\cf5 \strokec5 ]\cf4 \strokec4 .tolist\cf5 \strokec5 ())\cf4 \cb1 \strokec4 \
\cb3             all_true_labels.extend\cf5 \strokec5 (\cf4 \strokec4 ner_tags_reshaped\cf5 \strokec5 [\cf4 \strokec4 valid_indices\cf5 \strokec5 ]\cf4 \strokec4 .tolist\cf5 \strokec5 ())\cf4 \cb1 \strokec4 \
\
\cb3     avg_loss = total_loss / \cf7 \strokec7 len\cf5 \strokec5 (\cf4 \strokec4 data_loader\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     accuracy = \cf5 \strokec5 (\cf7 \strokec7 sum\cf5 \strokec5 (\cf11 \strokec11 int\cf5 \strokec5 (\cf4 \strokec4 pred == true\cf5 \strokec5 )\cf4 \strokec4  \cf2 \strokec2 for\cf4 \strokec4  pred\cf5 \strokec5 ,\cf4 \strokec4  true \cf10 \strokec10 in\cf4 \strokec4  \cf7 \strokec7 zip\cf5 \strokec5 (\cf4 \strokec4 all_predictions\cf5 \strokec5 ,\cf4 \strokec4  all_true_labels\cf5 \strokec5 ))\cf4 \strokec4  / \cf7 \strokec7 len\cf5 \strokec5 (\cf4 \strokec4 all_true_labels\cf5 \strokec5 ))\cf4 \strokec4  * \cf9 \strokec9 100\cf4 \cb1 \strokec4 \
\cb3     \cf2 \strokec2 return\cf4 \strokec4  avg_loss\cf5 \strokec5 ,\cf4 \strokec4  accuracy\cf5 \strokec5 ,\cf4 \strokec4  all_tokens\cf5 \strokec5 ,\cf4 \strokec4  all_true_labels\cf5 \strokec5 ,\cf4 \strokec4  all_predictions\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 def\cf4 \strokec4  \cf7 \strokec7 plot_precision_recall_curve\cf4 \strokec4 (\cf8 \strokec8 y_true\cf4 \strokec4 , \cf8 \strokec8 y_pred\cf4 \strokec4 )\cf5 \strokec5 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     precision\cf5 \strokec5 ,\cf4 \strokec4  recall\cf5 \strokec5 ,\cf4 \strokec4  _ = precision_recall_curve\cf5 \strokec5 (\cf4 \strokec4 y_true\cf5 \strokec5 ,\cf4 \strokec4  y_pred\cf5 \strokec5 ,\cf4 \strokec4  pos_label=\cf9 \strokec9 1\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     plt.figure\cf5 \strokec5 (\cf4 \strokec4 figsize=\cf5 \strokec5 (\cf9 \strokec9 8\cf5 \strokec5 ,\cf4 \strokec4  \cf9 \strokec9 6\cf5 \strokec5 ))\cf4 \cb1 \strokec4 \
\cb3     plt.plot\cf5 \strokec5 (\cf4 \strokec4 recall\cf5 \strokec5 ,\cf4 \strokec4  precision\cf5 \strokec5 ,\cf4 \strokec4  marker=\cf12 \strokec12 '.'\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     plt.title\cf5 \strokec5 (\cf12 \strokec12 'Precision-Recall curve'\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     plt.xlabel\cf5 \strokec5 (\cf12 \strokec12 'Recall'\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     plt.ylabel\cf5 \strokec5 (\cf12 \strokec12 'Precision'\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     plt.show\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 def\cf4 \strokec4  \cf7 \strokec7 plot_confusion_matrix\cf4 \strokec4 (\cf8 \strokec8 y_true\cf4 \strokec4 , \cf8 \strokec8 y_pred\cf4 \strokec4 , \cf8 \strokec8 labels\cf4 \strokec4 )\cf5 \strokec5 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     cm = confusion_matrix\cf5 \strokec5 (\cf4 \strokec4 y_true\cf5 \strokec5 ,\cf4 \strokec4  y_pred\cf5 \strokec5 ,\cf4 \strokec4  labels=labels\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     disp = ConfusionMatrixDisplay\cf5 \strokec5 (\cf4 \strokec4 confusion_matrix=cm\cf5 \strokec5 ,\cf4 \strokec4  display_labels=\cf5 \strokec5 [\cf4 \strokec4 index2tag\cf5 \strokec5 [\cf4 \strokec4 label\cf5 \strokec5 ]\cf4 \strokec4  \cf2 \strokec2 for\cf4 \strokec4  label \cf10 \strokec10 in\cf4 \strokec4  labels\cf5 \strokec5 ])\cf4 \cb1 \strokec4 \
\cb3     plt.figure\cf5 \strokec5 (\cf4 \strokec4 figsize=\cf5 \strokec5 (\cf9 \strokec9 10\cf5 \strokec5 ,\cf4 \strokec4  \cf9 \strokec9 10\cf5 \strokec5 ))\cf4 \cb1 \strokec4 \
\cb3     disp.plot\cf5 \strokec5 (\cf4 \strokec4 cmap=plt.cm.Blues\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     plt.show\cf5 \strokec5 ()\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf13 \cb3 \strokec13 # Training and evaluation loop\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 train_losses = \cf5 \strokec5 []\cf4 \cb1 \strokec4 \
\cb3 val_losses = \cf5 \strokec5 []\cf4 \cb1 \strokec4 \
\cb3 epochs = \cf9 \strokec9 10\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 for\cf4 \strokec4  epoch \cf10 \strokec10 in\cf4 \strokec4  \cf7 \strokec7 range\cf5 \strokec5 (\cf4 \strokec4 epochs\cf5 \strokec5 ):\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     avg_train_loss\cf5 \strokec5 ,\cf4 \strokec4  train_accuracy = train_epoch\cf5 \strokec5 (\cf4 \strokec4 model\cf5 \strokec5 ,\cf4 \strokec4  train_loader\cf5 \strokec5 ,\cf4 \strokec4  optimizer\cf5 \strokec5 ,\cf4 \strokec4  loss_fn\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     avg_val_loss\cf5 \strokec5 ,\cf4 \strokec4  val_accuracy = evaluate\cf5 \strokec5 (\cf4 \strokec4 model\cf5 \strokec5 ,\cf4 \strokec4  val_loader\cf5 \strokec5 ,\cf4 \strokec4  loss_fn\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     train_losses.append\cf5 \strokec5 (\cf4 \strokec4 avg_train_loss\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     val_losses.append\cf5 \strokec5 (\cf4 \strokec4 avg_val_loss\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\cb3     \cb1 \
\cb3     \cf7 \strokec7 print\cf5 \strokec5 (\cf6 \strokec6 f\cf12 \strokec12 'Epoch \cf5 \strokec5 \{\cf4 \strokec4 epoch+\cf9 \strokec9 1\cf5 \strokec5 \}\cf12 \strokec12 : Train Loss: \cf5 \strokec5 \{\cf4 \strokec4 avg_train_loss\cf9 \strokec9 :.4f\cf5 \strokec5 \}\cf12 \strokec12 , Train Acc: \cf5 \strokec5 \{\cf4 \strokec4 train_accuracy\cf9 \strokec9 :.2f\cf5 \strokec5 \}\cf12 \strokec12 %, Val Loss: \cf5 \strokec5 \{\cf4 \strokec4 avg_val_loss\cf9 \strokec9 :.4f\cf5 \strokec5 \}\cf12 \strokec12 , Vall Acc: \cf5 \strokec5 \{\cf4 \strokec4 val_accuracy\cf9 \strokec9 :.2f\cf5 \strokec5 \}\cf12 \strokec12 %'\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf13 \cb3 \strokec13 # Final evaluation on the test set with details\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 avg_test_loss\cf5 \strokec5 ,\cf4 \strokec4  test_accuracy\cf5 \strokec5 ,\cf4 \strokec4  test_tokens\cf5 \strokec5 ,\cf4 \strokec4  test_true_labels\cf5 \strokec5 ,\cf4 \strokec4  test_predictions = evaluate_with_details\cf5 \strokec5 (\cf4 \strokec4 model\cf5 \strokec5 ,\cf4 \strokec4  test_loader\cf5 \strokec5 ,\cf4 \strokec4  loss_fn\cf5 \strokec5 ,\cf4 \strokec4  index2token\cf5 \strokec5 ,\cf4 \strokec4  index2tag\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 print\cf5 \strokec5 (\cf6 \strokec6 f\cf12 \strokec12 'Test Loss: \cf5 \strokec5 \{\cf4 \strokec4 avg_test_loss\cf9 \strokec9 :.4f\cf5 \strokec5 \}\cf12 \strokec12 , Test Accuracy: \cf5 \strokec5 \{\cf4 \strokec4 test_accuracy\cf9 \strokec9 :.2f\cf5 \strokec5 \}\cf12 \strokec12 %'\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf13 \cb3 \strokec13 # Printing last 10 classification mistakes\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 mistakes = \cf5 \strokec5 [(\cf4 \strokec4 index2token\cf5 \strokec5 [\cf4 \strokec4 tok\cf5 \strokec5 ],\cf4 \strokec4  index2tag\cf5 \strokec5 [\cf4 \strokec4 pred\cf5 \strokec5 ],\cf4 \strokec4  index2tag\cf5 \strokec5 [\cf4 \strokec4 true\cf5 \strokec5 ])\cf4 \strokec4  \cf2 \strokec2 for\cf4 \strokec4  tok\cf5 \strokec5 ,\cf4 \strokec4  pred\cf5 \strokec5 ,\cf4 \strokec4  true \cf10 \strokec10 in\cf4 \strokec4  \cf7 \strokec7 zip\cf5 \strokec5 (\cf4 \strokec4 test_tokens\cf5 \strokec5 ,\cf4 \strokec4  test_predictions\cf5 \strokec5 ,\cf4 \strokec4  test_true_labels\cf5 \strokec5 )\cf4 \strokec4  \cf2 \strokec2 if\cf4 \strokec4  pred != true\cf5 \strokec5 ]\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 print\cf5 \strokec5 (\cf12 \strokec12 "\\nLast 10 Classification Mistakes on Test Set:"\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 for\cf4 \strokec4  token\cf5 \strokec5 ,\cf4 \strokec4  pred\cf5 \strokec5 ,\cf4 \strokec4  correct \cf10 \strokec10 in\cf4 \strokec4  mistakes\cf5 \strokec5 [\cf9 \strokec9 -50\cf5 \strokec5 :]:\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cf7 \strokec7 print\cf5 \strokec5 (\cf6 \strokec6 f\cf12 \strokec12 "Token: '\cf5 \strokec5 \{\cf4 \strokec4 token\cf5 \strokec5 \}\cf12 \strokec12 ', Predicted: '\cf5 \strokec5 \{\cf4 \strokec4 pred\cf5 \strokec5 \}\cf12 \strokec12 ', Correct: '\cf5 \strokec5 \{\cf4 \strokec4 correct\cf5 \strokec5 \}\cf12 \strokec12 '"\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf13 \cb3 \strokec13 # Unique labels for confusion matrix\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 unique_labels = np.unique\cf5 \strokec5 (\cf4 \strokec4 test_true_labels\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf13 \cb3 \strokec13 # Plotting the confusion matrix\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 plot_confusion_matrix\cf5 \strokec5 (\cf4 \strokec4 test_true_labels\cf5 \strokec5 ,\cf4 \strokec4  test_predictions\cf5 \strokec5 ,\cf4 \strokec4  labels=unique_labels\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\
\cb3 plot_precision_recall_curve\cf5 \strokec5 (\cf4 \strokec4 test_true_labels\cf5 \strokec5 ,\cf4 \strokec4  test_predictions\cf5 \strokec5 )\cf4 \cb1 \strokec4 \
\
}